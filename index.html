<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>TCC-Bench: Benchmarking the Traditional Chinese Culture Understanding Capabilities of MLLMs</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <style>
    .no-link-style {
      color: inherit;
      text-decoration: none;
    }
  </style>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">TCC-Bench: Benchmarking the Traditional Chinese Culture
              Understanding Capabilities of MLLMs</h1>
            <!-- <div class="is-size-5 publication-authors">
              
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">First Author</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Second Author</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Third Author</a>
                  </span>
                  </div> -->

                  <!-- <div class="is-size-5 publication-authors">
                    <span class="author-block">Institution Name<br>Conferance name and year</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div> -->

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2505.11275" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/TCC_Bench_supp.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/Morty-Xu/TCC-Bench" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://drive.google.com/file/d/1EbjSu_pTMQuIG7wqYZIQC5Y66DCClQdR/view?usp=sharinghttps:/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fa fa-database"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="content has-text-centered">
        <img src="static/image/TCC_sample.png" alt="composition" width="70%"/>
      <p>
        Samples of TCC-Bench. TCC-Bench has eight domains: Astronomy, Music, Custom, Architecture, Transportation, Diet, Clothing and Artifact.
      </p>
    </div>
  </div>
</section>
<!-- End teaser image -->

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            We present the <strong>T</strong>raditional <strong>C</strong>hinese <strong>C</strong>ulture understanding <strong>Bench</strong>mark, <strong>TCC-Bench</strong>, a bilingual (<em>i.e.</em>, Chinese and English) Visual Question Answering (VQA) benchmark specifically designed to evaluate the capabilities of MLLMs in understanding traditional Chinese culture. We customize eight knowledge domains that encompass key aspects of traditional Chinese culture. Moreover, the images within TCC-Bench are curated from museum artifacts, depictions of everyday life, comics, and other culturally significant materials, ensuring both visual diversity and cultural authenticity. Moreover, we introduce a semi-automated question generation method that reduces manual effort while ensuring the acquisition of high-quality data.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Overview</h2>
      We construct a multiple-choice VQA benchmark to evaluate the ability of current MLLMs to understand traditional Chinese culture. We divide the questions into eight domains: Astronomy, Music, Custom, Architecture, Transportation, Diet, Clothing and Artifact. To ensure the high quality of the benchmark, six adults are recruited for image collection and question generation. They all have bachelor's degrees or above and have extensive experience living in a Chinese cultural context. We design a semi-automated question generation pipeline to reduce manual labor costs. To facilitate the analysis of the model’s understanding of traditional Chinese culture across different languages, our dataset provides bilingual questions, options, and explanations.
      <div class="hero-body has-text-centered">
        <img src="static/image/pipline.png" alt="composition" width="70%"/>
    </div>
    </div>
  </div>
</section>

<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Statistics</h2>
      Our TCC-Bench comprises 675 images and 860 high-quality questions. Each question is accompanied by four carefully designed options, with only one correct answer, resulting in a total of 3,440 options. On average, the option length is 3.2 Chinese characters or 2.3 English words. The accompanying explanations average 20.9 Chinese characters or 15.9 English words, offering comprehensive insights into the traditional Chinese cultural knowledge underpinning each question. Furthermore, we analyze the distribution of questions across eight domains in our dataset. It can be observed that the question distribution in TCC-Bench is relatively balanced.      
      
      <div class="hero-body has-text-centered">
        <img src="static/image/category_pie.png" alt="composition" width="50%"/>
    </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Main Result</h2>
      To comprehensively evaluate MLLMs’ understanding of traditional Chinese culture, we select various MLLMs, including both open-source and closed-source models. For open-source MLLMs, we choose models with different parameter sizes. Specifically, the selected open-source models are: LLaVA-v1.6-7B, DeepSeek-VL-7B, Qwen2-VL-7B/72B, CogVLM2-19B, GLM-4V-9B, InternVL2.5-8B/78B. We use A800 GPUs to deploy and evaluate them. For closed-source MLLMs, we choose GPT-4o, Claude-3.7 Sonnet and Gemini-2.0 Flash. We evaluate them by calling the corresponding official APIs. The prompts are formatted as a multiple-choice setup. We use accuracy as the evaluation metric and prepare a rule-based answer extraction method.      
      <div class="hero-body has-text-centered">
        <img src="static/image/main_result.png" alt="composition" width="70%"/>
    </div>
    </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Error Analysis</h2>
      To analyze the underlying causes of the performance gap observed in MLLMs on TCC-Bench and to provide insights for their improvement, we extract the erroneous responses of GPT-4o under the CoT setting for manual annotations. Based on human annotations, we categorize the errors into four types: Visual Perceptual Error, Lack of Cultural Knowledge, Reasoning Error, and Reject to Answer.      
      <div class="hero-body has-text-centered">
        <img src="static/image/plot_error_pie.png" alt="composition" width="50%"/>
    </div>

    <div id="results-carousel" class="carousel results-carousel has-text-centered">
      <div class="item">
       <!-- Your image here -->
       <img src="static/image/error_VPE.png" alt="MY ALT TEXT"/>
       <h2 class="subtitle has-text-centered">
        Visual Perceptual Error.
       </h2>
     </div>
     <div class="item">
       <!-- Your image here -->
       <img src="static/image/error_knowledge.png" alt="MY ALT TEXT"/>
       <h2 class="subtitle has-text-centered">
        Lack of Cultural Knowledge.
       </h2>
     </div>
     <div class="item">
       <!-- Your image here -->
       <img src="static/image/error_reason.png" alt="MY ALT TEXT"/>
       <h2 class="subtitle has-text-centered">
        Reasoning Error.
      </h2>
    </div>
    <div class="item">
     <!-- Your image here -->
     <img src="static/image/error_reject.png" alt="MY ALT TEXT"/>
     <h2 class="subtitle has-text-centered">
      Reject to Answer.
     </h2>
   </div>
 </div>

    </div>
  </div>
</section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{xu2025tccbenchbenchmarkingtraditionalchinese,
        title={TCC-Bench: Benchmarking the Traditional Chinese Culture Understanding Capabilities of MLLMs}, 
        author={Pengju Xu and Yan Wang and Shuyuan Zhang and Xuan Zhou and Xin Li and Yue Yuan and Fengzhao Li and Shunyuan Zhou and Xingyu Wang and Yi Zhang and Haiying Zhao},
        year={2025},
        eprint={2505.11275},
        archivePrefix={arXiv},
        primaryClass={cs.MM},
        url={https://arxiv.org/abs/2505.11275}, 
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
